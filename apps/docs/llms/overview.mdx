---
title: "LLM Support"
description: "Language models supported by SpinAI"
---

SpinAI supports multiple LLMs for agent decision making:

- [OpenAI](/llms/openai)
- [Anthropic](/llms/anthropic)
- [Amazon Bedrock](/llms/bedrock)

Each LLM can be configured with custom settings like:

- Model selection
- Temperature
- Token limits
- API configuration

## Choosing an LLM

Consider these factors when choosing an LLM:

- Cost per token
- Response quality
- API reliability
- Token context limits

For those interested in leveraging the latest in AI technology, the addition of Amazon Bedrock to our supported LLMs offers an exciting new option. Bedrock provides a flexible and powerful tool for various AI-driven tasks, ensuring high-quality responses and reliable performance.

## Next Steps

<CardGroup>
  <Card title="OpenAI Setup" icon="openai" href="/llms/openai">
    Use OpenAI models
  </Card>
  <Card title="Anthropic Setup" icon="brain" href="/llms/anthropic">
    Use Claude models
  </Card>
  <Card title="Amazon Bedrock Setup" icon="aws" href="/llms/bedrock">
    Use Amazon Bedrock models
  </Card>
</CardGroup>

For detailed information on how to set up and use Amazon Bedrock with SpinAI, refer to the [Amazon Bedrock documentation](/llms/bedrock). This guide provides step-by-step instructions on configuring the Bedrock LLM for your needs, including model selection, API settings, and custom completion options to enhance your AI-driven applications.