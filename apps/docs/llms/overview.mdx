---
title: "LLM Support"
description: "Language models supported by SpinAI"
---

SpinAI supports multiple LLMs for agent decision making:

- [OpenAI](/llms/openai)
- [Anthropic](/llms/anthropic)
- [Amazon Bedrock](/llms/amazon-bedrock)

Each LLM can be configured with custom settings like:

- Model selection
- Temperature
- Token limits
- API configuration

## Choosing an LLM

Consider these factors when choosing an LLM:

- Cost per token
- Response quality
- API reliability
- Token context limits

## Next Steps

<CardGroup>
  <Card title="OpenAI Setup" icon="openai" href="/llms/openai">
    Use OpenAI models
  </Card>
  <Card title="Anthropic Setup" icon="brain" href="/llms/anthropic">
    Use Claude models
  </Card>
  <Card title="Amazon Bedrock Setup" icon="amazon" href="/llms/amazon-bedrock">
    Use Amazon Bedrock models
  </Card>
</CardGroup>

For detailed information on integrating Amazon Bedrock with your applications, refer to the [Amazon Bedrock documentation](/llms/amazon-bedrock). This addition provides insights into leveraging Amazon's robust and scalable infrastructure for your language model needs, offering another powerful option for your AI-driven applications.