---
title: "LLM Support"
description: "Language models supported by SpinAI"
---

SpinAI now supports a broader range of LLMs for agent decision making, providing more flexibility and options for your applications:

- [OpenAI](/llms/openai)
- [Anthropic](/llms/anthropic)
- [Cloudflare AI](/llms/cloudflare)
- Generic HTTP LLM (Documentation coming soon)

Each LLM can be configured with custom settings such as:

- Model selection
- Temperature
- Token limits
- API configuration

## Choosing an LLM

When selecting an LLM for your project, consider the following factors:

- Cost per token
- Response quality
- API reliability
- Token context limits
- Specific features or capabilities unique to each LLM

The choice of LLM can significantly impact the performance and cost-effectiveness of your application. 

## Next Steps

<CardGroup>
  <Card title="OpenAI Setup" icon="openai" href="/llms/openai">
    Use OpenAI models
  </Card>
  <Card title="Anthropic Setup" icon="brain" href="/llms/anthropic">
    Use Claude models
  </Card>
  <Card title="Cloudflare AI Setup" icon="cloud" href="/llms/cloudflare">
    Use Cloudflare AI models
  </Card>
</CardGroup>

Stay tuned for the upcoming documentation on integrating Generic HTTP LLMs, which will offer guidance on connecting any LLM over HTTP to SpinAI.