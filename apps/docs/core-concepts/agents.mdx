---
title: "Agents"
description: "AI agents that coordinate actions to achieve goals"
---

# Agents

Agents are the core building blocks of SpinAI. They combine LLMs (Large Language Models) with actions to solve tasks. With the addition of Amazon Bedrock LLMs, agents can now leverage a wider range of AI models for various applications.

## Quick Start

```typescript
import { createAgent, createOpenAILLM } from "spinai";
import { searchProducts, createOrder } from "./actions";

// Initialize your LLM
const llm = createOpenAILLM({
  apiKey: process.env.OPENAI_API_KEY,
});

// Create an agent
const agent = createAgent({
  instructions: "You are a helpful shopping assistant",
  actions: [searchProducts, createOrder],
  llm,
});

// Use the agent
const { response } = await agent({
  input: "Find me a red t-shirt under $30",
});
```

## Configuration Options

### Agent Creation Parameters

| Parameter        | Type                                        | Required | Description                                         |
| ---------------- | ------------------------------------------- | -------- | --------------------------------------------------- |
| `instructions`   | `string`                                    | Yes      | Instructions that guide the agent's behavior        |
| `actions`        | `Action[]`                                  | Yes      | Array of actions the agent can perform              |
| `llm`            | `BaseLLM`                                   | Yes      | Language model for decision making                  |
| `spinApiKey`     | `string`                                    | No       | API key for SpinAI dashboard integration            |
| `agentId`        | `string`                                    | No       | Unique identifier for the agent in SpinAI dashboard |
| `debug`          | `"none" \| "default" \| "verbose" \| "all"` | No       | Debug logging level                                 |
| `responseFormat` | `JSONSchema`                                | No       | Schema for structured responses, defaults to string |

### Agent Execution Parameters

| Parameter            | Type                  | Required | Description                      |
| -------------------- | --------------------- | -------- | -------------------------------- |
| `input`              | `string`              | Yes      | User input or task description   |
| `state`              | `Record<string  any>` | No       | Initial state for the execution  |
| `externalCustomerId` | `string`              | No       | Customer identifier for tracking |

### Return Values

| Parameter         | Type                  | Description                                         |
| ----------------- | --------------------- | --------------------------------------------------- |
| `response`        | `T \| string`         | Agent's response (typed if responseFormat provided) |
| `totalCostCents`  | `number`              | Total cost of LLM calls in cents                    |
| `totalDurationMs` | `number`              | Total execution time in milliseconds                |
| `sessionId`       | `string`              | Unique identifier for the conversation              |
| `interactionId`   | `string`              | Unique identifier for this specific interaction     |
| `state`           | `Record<string, any>` | Final state after execution                         |

## Amazon Bedrock LLM Agents

SpinAI now supports Amazon Bedrock LLMs, providing more flexibility and options for your agents. To use Amazon Bedrock LLMs, you can initialize your LLM as follows:

```typescript
import { createAgent, createBedrockLLM } from "spinai";

// Initialize your Bedrock LLM
const llm = createBedrockLLM({
  region: "us-west-2",
  access_key: process.env.AWS_ACCESS_KEY_ID,
  secret_key: process.env.AWS_SECRET_ACCESS_KEY,
  model: "your-model-name", // Optional: Defaults to a general-purpose model
});

// Create an agent with Bedrock LLM
const agent = createAgent({
  instructions: "You are a knowledgeable assistant",
  actions: [/* your actions here */],
  llm,
});

// Use the agent
const { response } = await agent({
  input: "Explain quantum computing",
});
```

This integration allows for the use of Amazon Bedrock's powerful models in your SpinAI agents, enabling a wide range of new applications and capabilities.

## Use Cases

### 1. Basic Agent

Simple agent that responds to queries:

```typescript
const agent = createAgent({
  instructions: "You are a helpful assistant",
  actions: [searchKnowledge, respondToUser],
  llm,
});

const { response } = await agent({
  input: "How do I reset my password?",
});
```

### 2. Structured Responses

Agent that returns typed data:

```typescript
interface OrderStatus {
  orderId: string;
  status: "pending" | "shipped" | "delivered";
  estimatedDelivery?: string;
}

const orderAgent = createAgent<OrderStatus>({
  instructions: "Track order status",
  actions: [getOrderDetails],
  llm,
  responseFormat: {
    type: "object",
    properties: {
      orderId: { type: "string" },
      status: { type: "string", enum: ["pending", "shipped", "delivered"] },
      estimatedDelivery: { type: "string" },
    },
    required: ["orderId", "status"],
  },
});
```

### 3. Dashboard Integration

Agent with monitoring enabled:

```typescript
const agent = createAgent({
  instructions: "Handle customer support",
  actions: [getCustomer, createTicket],
  llm,
  spinApiKey: process.env.SPINAI_API_KEY,
  agentId: "support-agent",
  debug: "verbose",
});

const { response, totalCostCents } = await agent({
  input: "I need help with my order",
  externalCustomerId: "customer_123",
});
```

### 4. Session Management with Reruns

Maintaining context across interactions:

```typescript
// Initial interaction
const { response, sessionId, state } = await agent({
  input: "Create a ticket for my broken laptop",
  state: { customerId: "123" },
});

// Follow-up using .rerun()
const { response: updatedResponse } = await agent.rerun({
  sessionId: sessionId,
  input: "Add that it's a MacBook Pro",
  state: state,
});
```

## Debug Logging

Different debug levels provide varying amounts of information:

| Level     | Information Shown             |
| --------- | ----------------------------- |
| `none`    | No logging                    |
| `default` | Basic flow and metrics        |
| `verbose` | Adds reasoning and parameters |
| `all`     | Adds full prompts and details |

Example output (default level):

```bash
ðŸ¤– Planning next actions (took 234ms, cost 0.5Â¢)
âš¡ Executing getCustomerInfo (took 123ms)
   Parameters: {"customerId": "123"}
ðŸ“Š Task complete (took 892ms, cost 1.2Â¢)
```

## Best Practices

1. **Clear Instructions**

   ```typescript
   instructions: "You are a support agent that helps users with order issues";
   ```

2. **Focused Action Sets**

   ```typescript
   actions: [getCustomerInfo, getOrderStatus, createTicket];
   ```

3. **State Management**
   ```typescript
   state: {
     customerId: "123",
     region: "US",
   }
   ```

## Next Steps

<CardGroup>
  <Card title="Actions" icon="puzzle-piece" href="/core-concepts/actions">
    Learn about creating actions
  </Card>
  <Card title="Task Loop" icon="arrows-spin" href="/core-concepts/task-loop">
    Understand how agents make decisions
  </Card>
</CardGroup>